{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YES_TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBYpuiAkHdpz",
        "outputId": "b44e0408-0415-4aa1-bc30-b20e0ee187bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#--------------IMPORTS AND GLOBALS---------------------\n",
        "\n",
        "# installs two python modules required\n",
        "!pip install faker\n",
        "!pip install ordered-set\n",
        "\n",
        "# required imports\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import calendar\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from faker import Faker\n",
        "import re\n",
        "import datetime\n",
        "from dateutil.relativedelta import *\n",
        "import inflect\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from ordered_set import OrderedSet\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "# global initialisations\n",
        "fake = Faker() # initialises faker module for date generation\n",
        "inf = inflect.engine() # initialises inflect for ordinal number conversion\n",
        "MAX_LENGTH = 45 # sets max length of input sequences to 45\n",
        "LEARNING_RATE = 0.01\n",
        "TEACHER_FORCING = True\n",
        "\n",
        "# if wanting to both train and validate model on generated data, set TRAINING to true\n",
        "# otherwise only validation on model will be performed \n",
        "TRAINING = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/6c/437383461986cc472b6ee001138ad637f638349e409a8fc21100fccd089d/Faker-4.14.0-py3-none-any.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 993kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from faker) (2.8.1)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from faker) (1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.4->faker) (1.15.0)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-4.14.0\n",
            "Collecting ordered-set\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/ab/8252360bfe965bba31ec05112b3067bd129ce4800d89e0b85613bc6044f6/ordered-set-4.0.2.tar.gz\n",
            "Building wheels for collected packages: ordered-set\n",
            "  Building wheel for ordered-set (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ordered-set: filename=ordered_set-4.0.2-py2.py3-none-any.whl size=8209 sha256=c3196e773710e854e570dda8ecada05f180b12bb16163b03836e6d521c818e4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/c6/9b/651d8a21d59b51a75ab9c070838f9231b8126421bc0569af47\n",
            "Successfully built ordered-set\n",
            "Installing collected packages: ordered-set\n",
            "Successfully installed ordered-set-4.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqHqTi6BII33"
      },
      "source": [
        "#-----------------DICTIONARY-----------------\n",
        "\n",
        "# create dictionary of characters \n",
        "vocab = OrderedSet() # uses ordered set to maintain order within set\n",
        "vocab.add('<SOS>') # adds start of sentence token\n",
        "vocab.add('<EOS>') # adds end of sentence token\n",
        "\n",
        "myfile = open('alphabet.txt', encoding=\"utf8\")  # opens alphabet txt file\n",
        "for line in myfile:\n",
        "    for word in line:\n",
        "        vocab.update(word) # adds each character from alphabet file to the vocab set\n",
        "myfile.close()\n",
        "\n",
        "ix2word = dict(enumerate(vocab)) # creates dictionary of vocab set, an index for each word in the vocab\n",
        "\n",
        "ix2word.update({len(ix2word): '<UNK>'}) # adds unknown character token\n",
        "\n",
        "word2ix = {v: k for k, v in ix2word.items()} # creates opposite word to index dictionary"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTfd9eihIKMM"
      },
      "source": [
        "#----------DATE GENERATION FUNCTIONS------------------\n",
        "\n",
        "# functions for generating and retrieving parts of input temporal expression sentences \n",
        "\n",
        "# takes randomly generated input number to determine form of day of week returned \n",
        "def getDayOfWeek(r):\n",
        "    # uses faker method day_of_week() to obtain a random day of the week\n",
        "    if r == 0: return fake.day_of_week() + \" \" # full - Monday\n",
        "    elif r == 1: return fake.day_of_week()[0:3] + \" \" # shortened - Mon\n",
        "    elif r == 2: return fake.day_of_week()[0:3] + '. ' # abbreviated - Mon.\n",
        "    else: return \"\" # returns nothing\n",
        "  \n",
        "# returns random time of day w/ optional timezone\n",
        "def getTime(r):\n",
        "    if r == 0:\n",
        "        r = random.randint(1, 12) # generates random hour in 12 hour clock\n",
        "        r2 = random.randint(0,3) # random number generated to determine the form of the returned time\n",
        "        if r2 == 0: return str(r) + \" am\" + getTimeZone()  # 12 am PT\n",
        "        elif r2 == 1: return str(r) + \" pm\" + getTimeZone() # 12 pm\n",
        "        elif r2 == 2: return str(r) + \" AM\" + getTimeZone() # 12 AM\n",
        "        elif r2 == 3: return str(r) + \" PM\" + getTimeZone() # 12 PM ET\n",
        "    else: return \"\"\n",
        "    \n",
        "# returns a US timezone or no timezone\n",
        "def getTimeZone():\n",
        "    r = random.randint(0,14) # generates random number to detemine which, if any, timezone is returned, weighted to mostly not return one\n",
        "    if r == 0: return \" PT\" # pacific\n",
        "    elif r == 1: return \" MT\" # mountain\n",
        "    elif r == 2: return \" CT\" # central\n",
        "    elif r == 3: return \" ET\" # eastern\n",
        "    else: return \"\" # blank\n",
        "    \n",
        "# returns a numerical day in the month using faker method day_of_month()\n",
        "def getDay():\n",
        "    return fake.day_of_month() # DD\n",
        "\n",
        "# separate method to generate various forms of days, takes input numerical day and random number to determine form\n",
        "# a tuple of the new day form and the original input day form is returned so YYYY-MM-DD label can be formed too \n",
        "def convertDay(d,r):\n",
        "    if r == 0: return (d,d) # 05\n",
        "    elif r == 1: return (d.lstrip(\"0\"),d) # 5\n",
        "    elif r == 2: return (inf.ordinal(int(d.lstrip(\"0\"))),d) # 5th\n",
        "    elif r == 3: return (inf.number_to_words(inf.ordinal(int(d.lstrip(\"0\")))).capitalize(),d) # fifth\n",
        "    \n",
        "# returns random month tuple of the year in various forms with faker month()\n",
        "def getMonth(r):\n",
        "    m = fake.month() # generates month in form MM\n",
        "\n",
        "    if r == 0: return (m, m) # 01\n",
        "    elif r == 1: return (m.lstrip(\"0\"), m) # 1, 01\n",
        "    elif r == 2: return (calendar.month_name[int(m)], m) # January , 01\n",
        "    elif r == 3: return (calendar.month_abbr[int(m)], m) # Jan, 01\n",
        "    #elif r == 4: return (calendar.month_abbr[int(m)] + '.', m) # Jan., 01\n",
        "\n",
        "# returns random year tuple with faker year(), begins with 1970\n",
        "def getYear(r):\n",
        "    y = fake.year() # generates year in form YYYY\n",
        "\n",
        "    if r == 0: return (y,y) # 1999\n",
        "    elif r == 1: return (y[-2:], y) # 99\n",
        "\n",
        "# returns a random holiday of listed holidays, as well as their MM-DD form for label\n",
        "def getHoliday(r):\n",
        "    if r == 0: return (\"Christmas\", \"12-25\")\n",
        "    elif r == 1: return (\"Halloween\", \"10-31\")\n",
        "    elif r == 2: return (\"New Years Day\", \"01-01\")\n",
        "    elif r == 3: return (\"New Years Eve\", \"12-31\")\n",
        "    elif r == 4: return (\"Boxing Day\", \"12-26\")\n",
        "    elif r == 5: return (\"Valentines Day\", \"02-14\")\n",
        "    elif r == 6: return (\"April Fools Day\", \"04-01\")\n",
        "    elif r == 7: return (\"St Patricks Day\", \"03-17\")\n",
        "    elif r == 8: return (\"All Saints Day\", \"11-01\")\n",
        "    elif r == 9: return (\"year-end\", \"12-31\")\n",
        "    elif r == 10: return (\"Independence Day\", \"07-04\")\n",
        "\n",
        "# returns random delimeter between parts of numerical date formats\n",
        "def getDivider(r):\n",
        "    if r == 0: return '/'\n",
        "    elif r == 1: return '-'\n",
        "    elif r == 2: return '.'\n",
        "    elif r == 3: return ''\n",
        "    elif r == 4: return ' '\n",
        "\n",
        "# returns random relative expression interval word\n",
        "def getRelativeInterval(r):\n",
        "    # 0\n",
        "    if r == 0: return \"today\"\n",
        "    elif r == 1: return \"now\"\n",
        "    elif r == 2: return \"this morning\"\n",
        "    elif r == 3: return \"this afternoon\"\n",
        "    elif r == 4: return \"this evening\"\n",
        "    elif r == 5: return \"tonight\"\n",
        "    elif r == 6: return getTime(0)\n",
        "    # +1\n",
        "    elif r == 7: return \"tomorrow\"\n",
        "    elif r == 8: return \"next \"\n",
        "    elif r == 9: return \" later\"\n",
        "    elif r == 10: return \" after\"\n",
        "    # -1\n",
        "    elif r == 11: return \"yesterday\"\n",
        "    elif r == 12: return \"last \"\n",
        "    elif r == 13: return \"previous \"\n",
        "    elif r == 14: return \" before\"\n",
        "    elif r == 15: return \" earlier\"\n",
        "    # -2\n",
        "    elif r == 16: return \"day before yesterday\"\n",
        "    # +2\n",
        "    elif r == 17: return \"day after tomorrow\"\n",
        "\n",
        "# returns random relative expression words\n",
        "def getRelativeWord(r):\n",
        "    if r == 0: return \"next year\"\n",
        "    elif r == 1: return \"last year\" \n",
        "    elif r == 13: return \"this\"\n",
        "    elif r == 14: return \"next\"\n",
        "    elif r == 15: return \"coming\"\n",
        "    elif r == 16: return \"last\"\n",
        "    elif r == 17: return \"previous\"\n",
        "    elif r == 18: return \"start of the \"\n",
        "    elif r == 19: return \"beginning of the \"\n",
        "    elif r == 20: return \"end of the \"\n",
        "\n",
        "# returns random measurement of time    \n",
        "def getMeasurement(r):\n",
        "    if r == 0: return \" days\"\n",
        "    elif r == 1: return \" weeks\"\n",
        "    elif r == 2: return \" months\"\n",
        "    elif r == 3: return \" years\"\n",
        "\n",
        "# returns random relative words\n",
        "def getRelativeMod(r):\n",
        "    if r == 0: return \" ago\"\n",
        "    elif r == 1: return \" from now\"\n",
        "    elif r == 2: return \"in \"\n",
        "    elif r == 3: return \"last\"\n",
        "    elif r == 4: return \"next\"\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOL4oY81ILbr"
      },
      "source": [
        "#--------- HELPER FUNCTIONS--------------\n",
        "\n",
        "# uses datetime object to verify legimate dates have been generated, recurses and decreases day value until legit date formed\n",
        "def verifyDate(d, m): # takes day and month\n",
        "    date = m + \"-\" + d # forms date in MM-DD\n",
        "    try:\n",
        "        datetimeobj = datetime.datetime.strptime(date, \"%m-%d\").date() # creates datetime object of MM-DD\n",
        "        return (d) # returns the valid day \n",
        "    except ValueError: # checks for value error\n",
        "        return verifyDate(str(int(d)-1), m) # recurses and decreases day value by 1\n",
        "        \n",
        "# allows adding and subtracting of days/weeks/months/years from dates using datetime object functionality\n",
        "def dateArithmetic(d, m, y, change, measurement): # takes day, month, year, numerical change value, measurement of time to change\n",
        "    datetime_date = datetime.datetime.strptime(y + \"-\" + m + \"-\" + d, \"%Y-%m-%d\").date() # creates datetime object\n",
        "\n",
        "    # if statement block checks which measurement is to be used, and increases/decreases off change value\n",
        "    if measurement == \"d\":\n",
        "        diff = datetime.timedelta(days=change)\n",
        "    elif measurement == \"w\":\n",
        "        diff = datetime.timedelta(weeks=change)\n",
        "    elif measurement == \"m\":\n",
        "        diff = relativedelta(months=change)\n",
        "    elif measurement == \"y\":\n",
        "        diff = relativedelta(years=change)\n",
        "    \n",
        "    return ((datetime_date + diff).strftime(\"%Y-%m-%d\")) # converts new datetime back to string and returns\n",
        "    \n",
        "# returns closest year to the current date\n",
        "# IS NOT USED\n",
        "def getClosestYear(nd, nm, y, rd):\n",
        "    ref = datetime.datetime.strptime(rd[1:11], \"%Y-%m-%d\").date()\n",
        "    y = str(int(y)-2)\n",
        "    mn = 1000\n",
        "    \n",
        "    for i in range(3):\n",
        "        y = str(int(y)+1)\n",
        "        date = datetime.datetime.strptime(y+\"-\"+nm+\"-\"+nd, \"%Y-%m-%d\").date()\n",
        "        diff = abs((date - ref).days)\n",
        "        if diff < mn:\n",
        "            mn = abs((date - ref).days)\n",
        "            mn_year = y\n",
        "            \n",
        "    return mn_year\n",
        "\n",
        "# retrieves yyyy-mm-dd form of the start/end of a month/year\n",
        "def getStartEnd(m, y, measurement, start): # takes month value, year value, month/year measurement, and boolean meaning start or end\n",
        "    if measurement == \"month\":\n",
        "        if start:\n",
        "            return y + \"-\" + m + \"-\"+ \"01\"\n",
        "        else:\n",
        "            d = calendar.monthrange(int(y), int(m))[1] # uses calendar module monthrange method to obtain the final day of the input month\n",
        "            return y + \"-\" + m + \"-\" + str(d)\n",
        "    elif measurement == \"year\":\n",
        "        if start:\n",
        "            return y + \"-\" + \"01-01\"\n",
        "        else:\n",
        "            return y + \"-\" + \"12-31\"\n",
        "\n",
        "# pads input sequences with leading zeroes to a specified length\n",
        "def padInput(data, seq_len):\n",
        "    padded = np.zeros((len(data), seq_len),dtype=int)\n",
        "    for ind, seq in enumerate(data):\n",
        "        if len(seq) != 0:\n",
        "            padded[ind, -len(seq):] = np.array(seq)[:seq_len]\n",
        "    return padded"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T26fmqF0INNs"
      },
      "source": [
        "#------------GENERATE DATA-------------\n",
        "\n",
        "# function takes max_range - total number of examples to generate, and ratios - list of how many examples to generate per subcategory\n",
        "def genData(max_range, ratios):\n",
        "    data = [] # data list\n",
        "    labels = [] # labels list\n",
        "    count = 0 # count incremented at each iteration\n",
        "    expr_types = [0,0,0,0,0,0,0,0,0,0] # list holding the number of expressions generated per subclass\n",
        "\n",
        "    for x in range(0, max_range): # iterates max_range times to generate max_range expressions\n",
        "    \n",
        "        # obtains a month, day, year value calling previously defined functions to create a reference date\n",
        "        month = getMonth(random.randint(0,3))\n",
        "        day = verifyDate(getDay(), month[1])\n",
        "        year = getYear(0)\n",
        "        ref_date = \"<\" + year[1] + \"-\" + month[1] + \"-\" + day + \">\" # creates ref date in form <YYYY-MM-DD>\n",
        "\n",
        "        # ---------ABSOLUTE EXPRESSIONS--------------\n",
        "        # HOLIDAY EXPRESSIONS \n",
        "        if count < ratios[0]: # creates holiday expressions up to a certain point\n",
        "\n",
        "            # obtains random holiday and year, creates date and label\n",
        "\n",
        "            hol = getHoliday(random.randint(0,10))\n",
        "            year = getYear(random.randint(0,1))\n",
        "            div = getDivider(4)\n",
        "            date = hol[0] + div + year[0] + \" \" + ref_date\n",
        "            label = year[1] + '-' + hol[1]\n",
        "            expr_types[0]+=1\n",
        "\n",
        "        # US DATE EXPRESSIONS\n",
        "        elif count < ratios[1]:\n",
        "            # generates random month\n",
        "            month = getMonth(random.randint(0,3))\n",
        "                \n",
        "            if bool(re.search(r'\\d', month[0])): # if numerical month\n",
        "                year = getYear(random.randint(0,1)) # gets year (not including apostrophe eg '19)\n",
        "                day = convertDay(verifyDate(getDay(), month[1]), random.randint(0,1))\n",
        "                div = getDivider(random.randint(0,1)) # gets non space divider\n",
        "                dow = getDayOfWeek(6) # gets blank day of week\n",
        "                \n",
        "                \n",
        "            else: # textual month\n",
        "                year = getYear(random.randint(0,1))\n",
        "                day = convertDay(verifyDate(getDay(), month[1]), random.randint(0,3))\n",
        "                div = getDivider(4) # get space divider\n",
        "                dow = getDayOfWeek(random.randint(0,6)) # gets day of week (can be blank)\n",
        "            \n",
        "            date = month[0] + div + day[0] + div + year[0] + \" \" + ref_date # us date format\n",
        "            label = year[1] + \"-\" + month[1] + \"-\" + day[1]\n",
        "            expr_types[1]+=1\n",
        "            \n",
        "        # DOCUMENT CREATION CODE \n",
        "        elif count < ratios[2]: \n",
        "            year = getYear(random.randint(0,1)) # gets year\n",
        "            month = getMonth(0)\n",
        "            day = convertDay(verifyDate(getDay(), month[1]), 0)\n",
        "                \n",
        "            r = random.randint(0,1)\n",
        "            if r == 0:\n",
        "                date = year[1] + month[1] + day[1] + \" \" + ref_date # 19980505 format\n",
        "            else:\n",
        "                date = year[1][-2:] + month[1] + day[1] + \" \" + ref_date # 980505 format\n",
        "                \n",
        "            label = year[1] + \"-\" + month[1] + \"-\" + day[1]\n",
        "            expr_types[2]+=1       \n",
        "            \n",
        "        # ---------RELATIVE EXPRESSIONS--------------\n",
        "        # US DATE\n",
        "        elif count < ratios[3]:\n",
        "                \n",
        "            new_month = getMonth(random.randint(0,3))\n",
        "                \n",
        "            if bool(re.search(r'\\d', new_month[0])): # if numerical month\n",
        "                div = getDivider(random.randint(0,1)) # gets non space divider\n",
        "                new_day = convertDay(verifyDate(getDay(), new_month[1]), random.randint(0,1))\n",
        "                dow = getDayOfWeek(6) # gets blank day of week\n",
        "            else: # textual month\n",
        "                div = getDivider(4) # get space divider\n",
        "                new_day = convertDay(verifyDate(getDay(), new_month[1]), random.randint(0,3))\n",
        "                dow = getDayOfWeek(random.randint(0,6)) # gets day of week (can be blank)\n",
        "                \n",
        "            r = random.randint(0,1)\n",
        "            date = new_month[0] + div + new_day[0] + \" \" + ref_date # us date format\n",
        "                \n",
        "            label = year[1] + \"-\" + new_month[1] + \"-\" + new_day[1]\n",
        "            expr_types[3]+=1\n",
        "                \n",
        "        # HOLIDAYS\n",
        "        elif count < ratios[4]:\n",
        "                \n",
        "            hol = getHoliday(random.randint(0,10))\n",
        "            date = hol[0] + \" \" + ref_date\n",
        "            label = year[1] + '-' + hol[1]\n",
        "            expr_types[4]+=1\n",
        "                \n",
        "        # MISCELLANEOUS\n",
        "        elif count < ratios[5]:\n",
        "            r = random.randint(0,3)\n",
        "            measure = getMeasurement(r)[1:-1]\n",
        "            r = random.randint(0,17)\n",
        "            when = getRelativeInterval(r)\n",
        "            if r <= 6: # same day\n",
        "                date = when + \" \" + ref_date\n",
        "                label = year[1] + \"-\" + month[1] + \"-\" + day\n",
        "            elif r <= 10 and r > 6: # day after\n",
        "                if r == 7: \n",
        "                    date = when + \" \" + ref_date\n",
        "                    measure = \"day\"\n",
        "                elif r == 8: date = when + measure + \" \" + ref_date\n",
        "                else: date = measure + when + \" \" + ref_date\n",
        "                label = dateArithmetic(day, month[1], year[1], 1, measure[:1])\n",
        "            elif r <= 15 and r > 10: # day before\n",
        "                if r == 11: \n",
        "                    date = when + \" \" + ref_date\n",
        "                    measure = \"day\"\n",
        "                if r == 12:\n",
        "                    if measure == \"day\": date = when + \"night\" + \" \" + ref_date \n",
        "                    else: date = when + measure + \" \" + ref_date\n",
        "                elif r == 13: date = when + measure + \" \" + ref_date\n",
        "                elif r == 14 or r == 15: date = measure + when + \" \" + ref_date\n",
        "                label = dateArithmetic(day, month[1], year[1], -1, measure[:1])\n",
        "            elif r == 16: # day before yesterday\n",
        "                date = when + \" \" + ref_date\n",
        "                label = dateArithmetic(day, month[1], year[1], -2, \"d\")\n",
        "            elif r == 17: #day after tomorrow\n",
        "                date = when + \" \" + ref_date\n",
        "                label = dateArithmetic(day, month[1], year[1], 2, \"d\")\n",
        "            expr_types[5]+=1\n",
        "                \n",
        "        # US DATE\n",
        "        elif count < ratios[6]:\n",
        "            r = random.randint(0,1)\n",
        "            dow = getDayOfWeek(random.randint(0,6))\n",
        "            div = getDivider(4)\n",
        "            new_month = getMonth(random.randint(2,3))\n",
        "            new_day = verifyDate(getDay(), month[1])\n",
        "            if r == 0:\n",
        "                date = new_month[0] + div +  new_day + \" \" + getRelativeWord(0) + \" \" + ref_date # US next year\n",
        "                label = str(int(year[1]) + 1) + \"-\" + new_month[1] + \"-\" + new_day\n",
        "            elif r == 1:\n",
        "                date = new_month[0] + div +  new_day + \" \" + getRelativeWord(1) + \" \" + ref_date # US last year\n",
        "                label = str(int(year[1]) - 1) + \"-\" + new_month[1] + \"-\" + new_day\n",
        "            expr_types[6]+=1\n",
        "        \n",
        "        # HOLIDAYS\n",
        "        elif count < ratios[7]:\n",
        "            \n",
        "            hol = getHoliday(random.randint(0,10))\n",
        "            r = random.randint(13,17)\n",
        "            when = getRelativeWord(r)\n",
        "            \n",
        "            date = when + \" \" + hol[0] + \" \" + ref_date\n",
        "            label = year[1] + \"-\" + hol[1]\n",
        "            \n",
        "            if r < 16: # future (next/coming/this)\n",
        "                if (ref_date[1:11] > label):\n",
        "                    new_year = str(int(year[1]) + 1) # increases year if future holiday is in the following year\n",
        "                    label = new_year + \"-\" + hol[1] # updates label\n",
        "            else: # past (previous/last)\n",
        "                if (ref_date[1:11] < label):\n",
        "                    new_year = str(int(year[1]) -1) # decreases year if past holiday is in previous year\n",
        "                    label = new_year + \"-\" + hol[1] # updates label\n",
        "            expr_types[7]+=1   \n",
        "                \n",
        "        # DATE ARITHMETIC\n",
        "        elif count < ratios[8]:\n",
        "            \n",
        "            r = random.randint(0,3)\n",
        "                \n",
        "            measurement = getMeasurement(r)\n",
        "            measurement_short = measurement[1:2]\n",
        "                \n",
        "            if r == 0:\n",
        "                change = random.randint(2,10) # 2-10 days\n",
        "            elif r == 1:\n",
        "                change = random.randint(1,6) # 1-6 weeks\n",
        "            elif r == 2:\n",
        "                change = random.randint(1,6) # 1-6 months\n",
        "            elif r == 3:\n",
        "                change = random.randint(1,5) # 1-5 years\n",
        "                \n",
        "            if change == 1:\n",
        "                measurement = measurement[:-1] # makes measurement word singular\n",
        "            \n",
        "            num_word = str(change)\n",
        "            \n",
        "            r = random.randint(0,2)\n",
        "            \n",
        "            if  r == 0:\n",
        "                date = num_word + measurement + getRelativeMod(0) + \" \" + ref_date # x days ago\n",
        "                label = dateArithmetic(day, month[1], year[1], -change, measurement_short)\n",
        "            elif r == 1:\n",
        "                date = num_word + measurement + getRelativeMod(1) + \" \" + ref_date # x days from now\n",
        "                label = dateArithmetic(day, month[1], year[1], change, measurement_short)\n",
        "            elif r == 2:\n",
        "                date = getRelativeMod(2) + num_word + measurement + \" \" + ref_date # in x days\n",
        "                label = dateArithmetic(day, month[1], year[1], change, measurement_short)\n",
        "            expr_types[8]+=1\n",
        "                \n",
        "        # START/END\n",
        "        elif count < ratios[9]:\n",
        "                \n",
        "            r = random.randint(18,21)\n",
        "            if r == 20 or r == 21:\n",
        "                r = 20\n",
        "                start = False \n",
        "            else: # 1/2 chance of start/beginning of\n",
        "                start = True\n",
        "            phrase = getRelativeWord(r)\n",
        "                \n",
        "            r = random.randint(0,13)\n",
        "            if r == 0:\n",
        "                measurement = getMeasurement(3)[1:-1] # gets year\n",
        "            else:\n",
        "                measurement = getMeasurement(2)[1:-1] # gets month\n",
        "                \n",
        "            if measurement == \"month\":\n",
        "                r = random.randint(0,12)\n",
        "                if r != 0: # obtains name of month as opposed to \"month\"\n",
        "                    new_month = getMonth(2)\n",
        "                    date = phrase[:-4] + new_month[0] + \" \" + ref_date\n",
        "                    label = getStartEnd(new_month[1], year[1], measurement, start)\n",
        "                else:\n",
        "                    date = phrase + measurement + \" \" + ref_date\n",
        "                    label = getStartEnd(month[1], year[1], measurement, start)\n",
        "            else:\n",
        "                date = phrase + measurement + \" \" + ref_date\n",
        "                label = getStartEnd(month[1], year[1], measurement, start)\n",
        "            expr_types[9]+=1\n",
        "                \n",
        "        # adds date to data list\n",
        "        data.append(date)\n",
        "        # adds label to label list\n",
        "        labels.append(label)\n",
        "        \n",
        "        # increments count\n",
        "        count+=1    \n",
        "\n",
        "    print(\"NUM EXPRESSIONS PER SUBCLASS: \",  expr_types)\n",
        "    shuffled_list = list(zip(data,labels)) # shuffles data and label lists\n",
        "    random.shuffle(shuffled_list)\n",
        "    return zip(*shuffled_list) # returns data and labels"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrwomPrqN6C3"
      },
      "source": [
        "#------------CONVERTS DATA TO TENSOR FORM-----------------\n",
        "\n",
        "# takes the training and testing data and converts the lists into tensors \n",
        "def dataToTensor(train_data, train_labels, test_data, test_labels, validation):\n",
        "    \n",
        "    # creates copies of the training and testing data\n",
        "    temp_train_data = train_data.copy()\n",
        "    temp_train_labels = train_labels.copy()\n",
        "    temp_test_data = test_data.copy()\n",
        "    temp_test_labels = test_labels.copy()\n",
        "\n",
        "    # converts the data to numerical form off the word2ix dictionary\n",
        "\n",
        "    for i, sentence in enumerate(temp_train_data):\n",
        "        temp_train_data[i] = [word2ix[word] if word in word2ix else 0 for word in sentence]\n",
        "        temp_train_data[i].append(1)\n",
        "\n",
        "    for i, sentence in enumerate(temp_test_data):\n",
        "        temp_test_data[i] = [word2ix[word] if word in word2ix else 0 for word in sentence]\n",
        "        temp_test_data[i].append(1)\n",
        "    \n",
        "    for i, sentence in enumerate(temp_train_labels):\n",
        "        temp_train_labels[i] = [word2ix[word] if word in word2ix else 0 for word in sentence]\n",
        "        temp_train_labels[i].append(1)\n",
        "    \n",
        "    for i, sentence in enumerate(temp_test_labels):\n",
        "        temp_test_labels[i] = [word2ix[word] if word in word2ix else 0 for word in sentence]\n",
        "        temp_test_labels[i].append(1)\n",
        "\n",
        "\n",
        "    seq_len = 45  # The length that the sentences will be padded/shortened to\n",
        "    \n",
        "    # pads train and test data and labels\n",
        "    temp_train_data = padInput(temp_train_data, seq_len)\n",
        "    temp_test_data = padInput(temp_test_data, seq_len)    \n",
        "\n",
        "    if validation:\n",
        "        temp_train_labels = np.array(temp_train_labels)\n",
        "        temp_test_labels = np.array(temp_test_labels)\n",
        "    else:\n",
        "        temp_train_labels = padInput(temp_train_labels, 11)\n",
        "        temp_test_labels = padInput(temp_test_labels, 11)     # 11 length of reference date <yyyy-mm-dd> \n",
        "\n",
        "    # tensor lists\n",
        "    ntrain_data = []\n",
        "    ntest_data = []\n",
        "\n",
        "    # converts training and testing data into tensors and appends to lists\n",
        "    for i in range(len(temp_train_data)):\n",
        "        ntrain_data.append(((torch.from_numpy(temp_train_data[i]).long()).view(-1, 1),(torch.from_numpy(temp_train_labels[i]).long()).view(-1, 1)))\n",
        "    for i in range(len(temp_test_data)):\n",
        "        ntest_data.append(((torch.from_numpy(temp_test_data[i]).long()).view(-1, 1),(torch.from_numpy(temp_test_labels[i]).long()).view(-1, 1)))\n",
        "\n",
        "    return ntrain_data, ntest_data # returns tensor lists"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YR6RFr7IQhk"
      },
      "source": [
        "#----------ENCODER AND DECODER------------\n",
        "\n",
        "# encoder class\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size) # embedding layer\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size) # gru layer\n",
        "\n",
        "    def forward(self, input, hidden): # foward pass\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self): # initialises hidden state\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device) # zeroes initial hidden state\n",
        "\n",
        "# decoder class\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size) # embedding layer\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length) # attention layer\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p) # dropout layer\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size) # gru layer\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size) # final linear layer\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs): # forward pass\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device) # zeroes initial hidden state"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EskOMxIVkFEw"
      },
      "source": [
        "# ---------------TRAIN PHASE FUNCTIONS-------------\n",
        "\n",
        "# two functions to print the time since the execution of the training began\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3TDJCkNO4Bz"
      },
      "source": [
        "#---------------TRAINING METHOD-----------------\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden() # initiliases first hidden state\n",
        "\n",
        "    # zeroes gradients on optimisers\n",
        "    encoder_optimizer.zero_grad() \n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # initialises inputs and outputs\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "        encoder_outputs[i] = encoder_output[0, 0]\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "\n",
        "    if TEACHER_FORCING: # teacher forcing has target label used as next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else: # without teacher forcing, predictions used as next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BgoatDhP1LL"
      },
      "source": [
        "#-----------------------TRAINING LOOP------------------\n",
        "\n",
        "def trainingPhase(encoder, decoder, max, print_every=1000, plot_every=100, learning_rate=LEARNING_RATE):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0 \n",
        " \n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    # gets list of pairs of data and labels in tensored training data\n",
        "    training_pairs = [(ntrain_data[i][0], ntrain_data[i][1]) for i in range(max)]\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    # loop through each example in training data\n",
        "    for i in range(1, max + 1):\n",
        "        # retrieves new pair from list\n",
        "        training_pair = training_pairs[i - 1]\n",
        "        # sets input and targets from pair\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        \n",
        "        # calls training method passing the input and target\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if i % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, i / max), i, i / max * 100, print_loss_avg))\n",
        "\n",
        "        if i % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMFMQVyjP2PI"
      },
      "source": [
        "#---------------------TEST METHOD-------------------------------\n",
        "\n",
        "def test(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = sentence\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(ix2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoaFkTlsP3pH"
      },
      "source": [
        "#---------------------TESTING LOOP-------------------------------\n",
        "def testPhase(encoder, decoder, n):\n",
        "    corr = 0 # int to store how many correct predictions made\n",
        "    print(\"NUMBER OF EXAMPLES: \", n)\n",
        "\n",
        "    for i in range(n): # begins loop\n",
        "        if i % (n/10) == 0:\n",
        "            print(f\"{(i/len(test_data))*100}% complete.\")\n",
        "        \n",
        "        pair = [(ntest_data[i][0], ntest_data[i][1])] # gets pair of example and label \n",
        "\n",
        "        # constructs string of target tensor with ix2word dict\n",
        "        outp = []\n",
        "        for j in range((len(pair[0][1]))-1):\n",
        "            if pair[0][1][j].item() != 0:\n",
        "                outp.append(ix2word[pair[0][1][j].item()])\n",
        "\n",
        "        targ_str = \"\".join(outp)\n",
        "        \n",
        "        # passes inp tensor to test function\n",
        "        output_words, attentions = test(encoder, decoder, pair[0][0])\n",
        "        output_sentence = ''.join(output_words) # constructs sentence from output words\n",
        "        \n",
        "        if output_sentence == targ_str: # if prediction equivalent to target\n",
        "            corr+=1 # correct prediction made\n",
        "\n",
        "    print(f\"{100}% complete.\")\n",
        "    print(\"\")\n",
        "    print(\"correct: \", corr, \" of \", n)\n",
        "    print(f\"acc: {(corr/n)*100:.4f}%\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHCgsxc7xQQX",
        "outputId": "6dad527a-99ee-4bd4-f3f0-334e5971359c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# RUN CELL IF USING GOOGLE DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufHKgaHvJ3Bp",
        "outputId": "50b497ad-4b0e-4b78-b7c1-8e391194a9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#--------------------GENERATE DATA-----------------------\n",
        "\n",
        "max_range =  125000 # total number of examples\n",
        "MAX_LENGTH = 45\n",
        "SOS_token = 0\n",
        "EOS_token = 1 \n",
        "train_perc = int(max_range * 0.8) # number of training examples\n",
        "test_perc =  max_range - train_perc  # number of validation exmamples\n",
        "\n",
        "# ratios list holds the indexes at which a new subcategory of expression should be generated\n",
        "ratios = [train_perc/10, 2*train_perc/10, 3*train_perc/10, 4*train_perc/10, 5*train_perc/10, 6*train_perc/10, 7*train_perc/10, 8*train_perc/10, 9*train_perc/10, train_perc]\n",
        "train_data, train_labels = genData(train_perc, ratios) # generates training data and labels\n",
        "print(\"LENGTH OF TRAINING LISTS: \", len(train_data))\n",
        "\n",
        "ratios = [test_perc/10, 2*test_perc/10, 3*test_perc/10, 4*test_perc/10, 5*test_perc/10, 6*test_perc/10, 7*test_perc/10, 8*test_perc/10, 9*test_perc/10, test_perc]\n",
        "test_data, test_labels = genData(test_perc, ratios)\n",
        "print(\"LENGTH OF TESTING LISTS: \", len(test_data))\n",
        "\n",
        "# converts data into tensors\n",
        "train_data = list(train_data)\n",
        "train_labels = list(train_labels)\n",
        "test_data = list(test_data)\n",
        "test_labels = list(test_labels)\n",
        "ntrain_data, ntest_data = dataToTensor(train_data, train_labels, test_data, test_labels, True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM EXPRESSIONS PER SUBCLASS:  [10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]\n",
            "LENGTH OF TRAINING LISTS:  100000\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500]\n",
            "LENGTH OF TESTING LISTS:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvwBG3bbP5Sl",
        "outputId": "c2f70e6d-3d04-4a28-a376-3bf4c24fca51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#-----------------TRAINING AND TESTING-----------------\n",
        "\n",
        "# initialise encoder and decoder classes\n",
        "hidden_size = 256\n",
        "enc = Encoder(len(ix2word), hidden_size).to(device)\n",
        "dec = Decoder(hidden_size, len(ix2word), dropout_p=0.1).to(device)\n",
        "\n",
        "print(\"------LOADING PREVIOUS MODEL------\")\n",
        "\n",
        "# IF USING GOOGLE DRIVE USE CURRENT PATHS\n",
        "# OTHERWISE UPLOAD MODELS TO COLAB LOCAL STORAGE AND CHANGE PATHS\n",
        "path = F\"/content/gdrive/My Drive/models/tf/encoder.pt\" # google drive path\n",
        "#path = 'encoder.pt' # local path\n",
        "enc.load_state_dict(torch.load(path))\n",
        "path = F\"/content/gdrive/My Drive/models/tf/decoder.pt\" # google drive path\n",
        "#path = 'decoder.pt' # local path\n",
        "dec.load_state_dict(torch.load(path))\n",
        "print(\"Successfully loaded encoder and decoder.\")\n",
        "print(\"\")\n",
        "\n",
        "if TRAINING: # trains model if training boolean set to true\n",
        "    print(\"------MODEL TRAINING------\")\n",
        "    trainIters(enc, dec, int(train_perc), print_every=(len(train_data)/50)) # calls training function\n",
        "    print(\"\")\n",
        "\n",
        "print(\"------GENERAL MODEL VALIDATION------\")\n",
        "testPhase(enc, dec, len(ntest_data)) # tests model\n",
        "print(\"\")\n",
        "\n",
        "if TRAINING:\n",
        "    print(\"------MODEL SAVING------\")\n",
        "    model_save_name = 'new_encoder.pt'\n",
        "    path = F\"/content/gdrive/My Drive/models/tf/{model_save_name}\" # google drive path\n",
        "    #path = 'new_encoder.pt' # local path\n",
        "    torch.save(enc.state_dict(), path)\n",
        "\n",
        "    model_save_name = 'new_decoder.pt'\n",
        "    path = F\"/content/gdrive/My Drive/models/tf/{model_save_name}\" # google drive path\n",
        "    #path = 'new_decoder.pt' # local path\n",
        "    torch.save(dec.state_dict(), path)\n",
        "    print(\"Successfully saved encoder and decoder.\")\n",
        "    print(\"\")\n",
        "\n",
        "print(\"------GENERATING VALIDATION SETS PER SUBCATEGORY------\")\n",
        "test_perc = 10000 # 10k examples per subcategory\n",
        "test_data_arr = []\n",
        "test_labels_arr = []\n",
        "for i in range(0,10): # generates data \n",
        "    if i < 1:\n",
        "        ratios[2] = test_perc + 1\n",
        "    ratios[i] = test_perc\n",
        "    test_data, test_labels = genData(test_perc, ratios)\n",
        "    test_data = list(test_data)\n",
        "    test_labels = list(test_labels)\n",
        "    test_data_arr.append(test_data)\n",
        "    test_labels_arr.append(test_labels)\n",
        "    ratios[i] = 0\n",
        "print(\"\")\n",
        "\n",
        "print(\"------MODEL VALIDATION ON EACH SUBCLASS------\")\n",
        "for i in range(0, 10):\n",
        "  test_data = test_data_arr[i]\n",
        "  test_labels = test_labels_arr[i]\n",
        "  ntrain_data, ntest_data = dataToTensor(train_data, train_labels, test_data, test_labels, True)\n",
        "\n",
        "  print(\"EXAMPLES OF EXPRESSION AND LABEL: \", test_data[1],\" | \",test_labels[1])\n",
        "  testPhase(enc, dec, len(ntest_data))\n",
        "  print(\"\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------LOADING PREVIOUS MODEL------\n",
            "Successfully loaded encoder and decoder.\n",
            "\n",
            "------GENERAL MODEL VALIDATION------\n",
            "NUMBER OF EXAMPLES:  25000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  23595  of  25000\n",
            "acc: 94.3800%\n",
            "\n",
            "------GENERATING VALIDATION SETS PER SUBCATEGORY------\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [10000, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 10000, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 0, 10000, 0, 0, 0, 0, 0, 0, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 0, 0, 10000, 0, 0, 0, 0, 0, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 0, 0, 0, 10000, 0, 0, 0, 0, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 0, 0, 0, 0, 10000, 0, 0, 0, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 0, 0, 0, 0, 0, 10000, 0, 0, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 0, 0, 0, 0, 0, 0, 10000, 0, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 0, 0, 0, 0, 0, 0, 0, 10000, 0]\n",
            "NUM EXPRESSIONS PER SUBCLASS:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 10000]\n",
            "\n",
            "------MODEL VALIDATION ON EACH SUBCLASS------\n",
            "Independence Day 2009 <1998-08-28>  |  2009-07-04\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9998  of  10000\n",
            "acc: 99.9800%\n",
            "\n",
            "January 21st 18 <1984-12-13>  |  2018-01-21\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9961  of  10000\n",
            "acc: 99.6100%\n",
            "\n",
            "19750617 <1987-02-27>  |  1975-06-17\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9971  of  10000\n",
            "acc: 99.7100%\n",
            "\n",
            "January 5th <1992-07-31>  |  1992-01-05\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9938  of  10000\n",
            "acc: 99.3800%\n",
            "\n",
            "April Fools Day <1978-06-01>  |  1978-04-01\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9917  of  10000\n",
            "acc: 99.1700%\n",
            "\n",
            "tonight <2003-09-24>  |  2003-09-24\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9416  of  10000\n",
            "acc: 94.1600%\n",
            "\n",
            "Dec 14 next year <1980-05-20>  |  1981-12-14\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9941  of  10000\n",
            "acc: 99.4100%\n",
            "\n",
            "this Boxing Day <2011-08-08>  |  2011-12-26\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9583  of  10000\n",
            "acc: 95.8300%\n",
            "\n",
            "in 4 years <1996-01-11>  |  2000-01-11\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  5663  of  10000\n",
            "acc: 56.6300%\n",
            "\n",
            "end of April <1993-01-22>  |  1993-04-30\n",
            "NUMBER OF EXAMPLES:  10000\n",
            "0.0% complete.\n",
            "10.0% complete.\n",
            "20.0% complete.\n",
            "30.0% complete.\n",
            "40.0% complete.\n",
            "50.0% complete.\n",
            "60.0% complete.\n",
            "70.0% complete.\n",
            "80.0% complete.\n",
            "90.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  9911  of  10000\n",
            "acc: 99.1100%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g9ti-Qw4Jec",
        "outputId": "2f554527-bdd0-4a9c-a7ea-ac29df0d3950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#----------------EVALUATE MODEL ON UNSEEN TEST DATA----------------\n",
        "\n",
        "enc = Encoder(len(ix2word), hidden_size).to(device)\n",
        "dec = Decoder(hidden_size, len(ix2word), dropout_p=0.1).to(device)\n",
        "\n",
        "print(\"------PREVIOUS MODEL LOADING------\")\n",
        "path = F\"/content/gdrive/My Drive/models/tf/encoder.pt\" # google drive path\n",
        "#path = 'encoder.pt' # local path\n",
        "enc.load_state_dict(torch.load(path))\n",
        "path = F\"/content/gdrive/My Drive/models/tf/decoder.pt\" # google drive path\n",
        "#path = 'decoder.pt' # local path\n",
        "dec.load_state_dict(torch.load(path))\n",
        "print(\"Successfully loaded encoder and decoder.\")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# initialises data and labels lists\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# opens and reads data, refdates and labels files into lists\n",
        "\n",
        "path = \"timebank_data.txt\"\n",
        "myfile = open(path, encoding=\"utf8\") # opens file\n",
        "for line in myfile:\n",
        "    data.append(line[:-1])\n",
        "myfile.close() \n",
        "\n",
        "\n",
        "path = \"timebank_dates.txt\"\n",
        "myfile = open(path, encoding=\"utf8\") # opens file\n",
        "count = 0\n",
        "for line in myfile:\n",
        "    data[count] = data[count] + \"<\" + line[:-1] + \">\" # formats file content into ref date form and appends to each expression in data list\n",
        "    count +=1\n",
        "myfile.close()\n",
        "\n",
        "\n",
        "path = \"timebank_labels.txt\"\n",
        "myfile = open(path, encoding=\"utf8\") # opens file\n",
        "for line in myfile:\n",
        "    labels.append(line[:-1])\n",
        "myfile.close()\n",
        "\n",
        "\n",
        "train_data = []\n",
        "train_labels = []\n",
        "test_data = data\n",
        "test_labels = labels\n",
        "# converts test data into tensors\n",
        "ntrain_data, ntest_data = dataToTensor(train_data, train_labels, test_data, test_labels, False)\n",
        "\n",
        "# model testing\n",
        "print(\"------MODEL TESTING ON TIMEBANK------\")\n",
        "testPhase(enc, dec, len(ntest_data))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------PREVIOUS MODEL LOADING------\n",
            "Successfully loaded encoder and decoder.\n",
            "\n",
            "------MODEL TESTING ON TIMEBANK------\n",
            "NUMBER OF EXAMPLES:  366\n",
            "0.0% complete.\n",
            "100% complete.\n",
            "\n",
            "correct:  348  of  366\n",
            "acc: 95.0820%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
